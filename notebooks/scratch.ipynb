{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pilco.policies import RBFPolicy, SineBoundedActionPolicy\n",
    "\n",
    "from pilco.agents.agents import EQGPAgent\n",
    "from pilco.costs.costs import EQCost\n",
    "from pilco.environments import Environment\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy: match moments (closed form and MC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_policy = RBFPolicy(2, 1, 5, dtype=tf.float32)\n",
    "rbf_policy.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All eigenvalues are postive: True\n",
      "mean_full:\n",
      "[[0.       0.       0.539999]]\n",
      "cov_full:\n",
      "[[ 1.          0.         -0.18453534]\n",
      " [ 0.          1.          0.01663259]\n",
      " [-0.18453534  0.01663259  0.10607606]]\n"
     ]
    }
   ],
   "source": [
    "loc = tf.zeros(2, dtype=tf.float32)\n",
    "cov = tf.eye(2, dtype=tf.float32)\n",
    "\n",
    "mean_full, cov_full = rbf_policy.match_moments(loc, cov)\n",
    "\n",
    "print('All eigenvalues are postive:', bool(tf.reduce_all(tf.cast(tf.linalg.eig(cov_full)[0], dtype=tf.float32) > 0)))\n",
    "\n",
    "print(f'mean_full:\\n{mean_full.numpy()}')\n",
    "print(f'cov_full:\\n{cov_full.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 954.11it/s]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10**3\n",
    "\n",
    "states = []\n",
    "actions = []\n",
    "\n",
    "for i in trange(num_samples):\n",
    "    \n",
    "    s = tf.random.normal(mean=0., stddev=1., shape=(2,))\n",
    "    \n",
    "    u = rbf_policy(s)\n",
    "    \n",
    "    states.append(s)\n",
    "    actions.append(u)\n",
    "    \n",
    "s = tf.convert_to_tensor(states)\n",
    "u = tf.convert_to_tensor(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC mean_full:\n",
      "[[ 0.00160797 -0.00733619  0.5346511 ]]\n",
      "MC cov_full:\n",
      "[[ 1.0191172   0.04218094 -0.1819982 ]\n",
      " [ 0.04218094  1.038064    0.01108719]\n",
      " [-0.1819982   0.01108719  0.10729006]]\n"
     ]
    }
   ],
   "source": [
    "su_samples = tf.concat([s, u[..., None]], axis=-1)\n",
    "\n",
    "print('MC mean_full:')\n",
    "mean_full = tf.reduce_mean(su_samples, axis=0)[None, ...]\n",
    "print(mean_full.numpy())\n",
    "\n",
    "print('MC cov_full:')\n",
    "cov_full = (tf.einsum('ij, ik -> jk', su_samples, su_samples) / su_samples.shape[0])\n",
    "cov_full = cov_full - (tf.einsum('ij, ik -> jk', mean_full, mean_full) / mean_full.shape[0])\n",
    "print(cov_full.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sine Bounded RBF Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_policy = RBFPolicy(2, 1, 5, dtype=tf.float32)\n",
    "sb_rbf_policy = SineBoundedActionPolicy(rbf_policy, lower=-2, upper=10)\n",
    "sb_rbf_policy.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All eigenvalues are postive: True\n",
      "mean_full:\n",
      "[[0.        0.        5.9844503]]\n",
      "cov_full:\n",
      "[[ 1.          0.         -1.0597148 ]\n",
      " [ 0.          1.         -0.45615625]\n",
      " [-1.0597148  -0.45615625  3.722326  ]]\n"
     ]
    }
   ],
   "source": [
    "loc = tf.zeros(2, dtype=tf.float32)\n",
    "cov = tf.eye(2, dtype=tf.float32)\n",
    "\n",
    "# mean_full_ = tf.convert_to_tensor([[ 0.,        0.,         -0.25994033]], dtype=tf.float32)\n",
    "# cov_full_ = tf.convert_to_tensor([[1.,         0.,         0.09250697],\n",
    "#  [0.,         1.,         0.06342697],\n",
    "#  [0.09250697, 0.06342697, 0.16243385]], dtype=tf.float32)\n",
    "\n",
    "# joint_dist_ = tfd.MultivariateNormalTriL(loc=mean_full_,\n",
    "#                                         scale_tril=tf.linalg.cholesky(cov_full_))\n",
    "\n",
    "mean_full, cov_full = sb_rbf_policy.match_moments(loc, cov)\n",
    "\n",
    "print('All eigenvalues are postive:', bool(tf.reduce_all(tf.cast(tf.linalg.eig(cov_full)[0], dtype=tf.float32) > 0)))\n",
    "\n",
    "print(f'mean_full:\\n{mean_full.numpy()}')\n",
    "print(f'cov_full:\\n{cov_full.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 792.39it/s]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10**3\n",
    "\n",
    "states = []\n",
    "actions = []\n",
    "\n",
    "for i in trange(num_samples):\n",
    "    \n",
    "#     samp = joint_dist_.sample()\n",
    "#     s = samp[0, :2]\n",
    "    s = tf.random.normal(mean=0., stddev=1., shape=(2,))\n",
    "    \n",
    "    u = sb_rbf_policy(s)\n",
    "    \n",
    "    states.append(s)\n",
    "    actions.append(u)\n",
    "    \n",
    "s = tf.convert_to_tensor(states)\n",
    "u = tf.convert_to_tensor(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC mean_full:\n",
      "[[-0.03008542 -0.01884396  6.001739  ]]\n",
      "MC cov_full:\n",
      "tf.Tensor(\n",
      "[[ 1.0014623   0.05778026 -1.0733577 ]\n",
      " [ 0.05778026  1.038319   -0.5239479 ]\n",
      " [-1.0733577  -0.5239479   3.3305779 ]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "su_samples = tf.concat([s, u[..., None]], axis=-1)\n",
    "\n",
    "print('MC mean_full:')\n",
    "mean_full = tf.reduce_mean(su_samples, axis=0)[None, ...]\n",
    "print(mean_full.numpy())\n",
    "\n",
    "print('MC cov_full:')\n",
    "cov_full = (tf.einsum('ij, ik -> jk', su_samples, su_samples) / su_samples.shape[0])\n",
    "cov_full = cov_full - (tf.einsum('ij, ik -> jk', mean_full, mean_full) / mean_full.shape[0])\n",
    "print(cov_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent: match moments (closed form and MC)\n",
    "\n",
    "## Add dummy data to agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(24)\n",
    "\n",
    "rbf_policy = RBFPolicy(state_dim=2,\n",
    "                       action_dim=1,\n",
    "                       num_rbf_features=5,\n",
    "                       dtype=tf.float64)\n",
    "\n",
    "sb_rbf_policy = SineBoundedActionPolicy(rbf_policy,\n",
    "                                        lower=-20,\n",
    "                                        upper=15)\n",
    "\n",
    "# rbf_policy.reset()\n",
    "sb_rbf_policy.reset()\n",
    "\n",
    "eq_cost = EQCost(target_loc=tf.ones((1, 3)),\n",
    "                 target_scale=1.,\n",
    "                 dtype=tf.float64)\n",
    "\n",
    "eq_agent = EQGPAgent(state_dim=2,\n",
    "                     action_dim=1,\n",
    "                     policy=sb_rbf_policy,\n",
    "                     cost=eq_cost,\n",
    "                     dtype=tf.float64)\n",
    "\n",
    "# Create pendulum environment from Gym\n",
    "env = Environment(name='Pendulum-v0')\n",
    "env.reset()\n",
    "\n",
    "num_episodes = 50\n",
    "num_steps = 1\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    \n",
    "    state = env.reset()\n",
    "    \n",
    "    state = np.array([np.pi, 8]) * (2 * np.random.uniform(size=(2,)) - 1)\n",
    "    env.env.env.state = state\n",
    "    \n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        \n",
    "        action = tf.random.uniform(shape=()) * 4. - 2\n",
    "        state, action, next_state = env.step(action[None].numpy())\n",
    "        \n",
    "        eq_agent.observe(state, action, next_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match moments analytically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state_loc = 1. * tf.ones(2, dtype=tf.float64)\n",
    "state_cov = 10. * tf.eye(2, dtype=tf.float64)\n",
    "\n",
    "# Match moments for the joint state-action distribution\n",
    "mean_full, cov_full = sb_rbf_policy.match_moments(state_loc, state_cov)\n",
    "\n",
    "# mean_full = 0. * tf.ones((1, 3), dtype=tf.float64)\n",
    "# cov_full = 1. * tf.eye(3, dtype=tf.float64)\n",
    "\n",
    "joint_dist = tfd.MultivariateNormalTriL(loc=mean_full,\n",
    "                                        scale_tril=tf.linalg.cholesky(cov_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match moments by MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 105.44it/s]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10**3\n",
    "\n",
    "means = []\n",
    "covs = []\n",
    "state_actions = []\n",
    "\n",
    "# MC approx\n",
    "for i in trange(num_samples):\n",
    "    \n",
    "    state_action = joint_dist.sample()\n",
    "    \n",
    "    #Note: mean is the expectation of the deltas!\n",
    "    mean, cov = eq_agent.gp_posterior_predictive(state_action)\n",
    "    means.append(mean)\n",
    "    \n",
    "    covs.append(cov)\n",
    "    state_actions.append(state_action)\n",
    "    \n",
    "means = tf.concat(means, axis=0)\n",
    "covs = tf.stack(covs, axis=0)\n",
    "state_actions = tf.stack(state_actions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cov[E(Δ | x)]:\n",
      "[[ 3.62445213e-05 -1.09271150e-04]\n",
      " [-1.05383661e-04  5.77354493e-04]]\n",
      "E[Cov(Δ | x)]:\n",
      "[[0.99857792 0.        ]\n",
      " [0.         0.99857792]]\n",
      "Cov[x, Δ]:\n",
      "[[-0.00130591  0.0063959 ]\n",
      " [ 0.00221726 -0.00497356]]\n",
      "Emp mean:\n",
      "[[1.00058466 0.99794347]]\n",
      "Emp cov:\n",
      "[[1.09960024e+01 8.50388573e-03]\n",
      " [8.50777322e-03 1.09892082e+01]]\n"
     ]
    }
   ],
   "source": [
    "emp_mean = tf.reduce_mean(means, axis=0)\n",
    "\n",
    "cov_mean_delta = tf.reduce_mean(means[:, None, :] * means[:, :, None], axis=0)\n",
    "cov_mean_delta = cov_mean_delta - emp_mean * tf.transpose(emp_mean)\n",
    "print(f'Cov[E(Δ | x)]:\\n{cov_mean_delta}')\n",
    "mean_cov_delta = tf.linalg.diag(tf.reduce_mean(covs, axis=[0, 1]))\n",
    "print(f'E[Cov(Δ | x)]:\\n{mean_cov_delta}')\n",
    "\n",
    "states = state_actions[:, :, :eq_agent.state_dim]\n",
    "emp_cross_cov = tf.reduce_mean(states * means[:, :, None], axis=0)\n",
    "emp_cross_cov = emp_cross_cov - tf.reduce_mean(states, axis=0) * tf.reduce_mean(means[:, :, None], axis=0)\n",
    "print(f\"Cov[x, Δ]:\\n{tf.transpose(emp_cross_cov)}\")\n",
    "\n",
    "emp_mean = tf.reduce_mean(means, axis=0) + mean_full[:, :eq_agent.state_dim]\n",
    "emp_cov = cov_full[:eq_agent.state_dim, :eq_agent.state_dim] \n",
    "emp_cov = emp_cov + cov_mean_delta + mean_cov_delta + emp_cross_cov + tf.transpose(emp_cross_cov)\n",
    "print(f\"Emp mean:\\n{emp_mean}\")\n",
    "print(f\"Emp cov:\\n{emp_cov}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cov diag components:\n",
      "[0.9975902 0.9975902]\n",
      "cov without cross cov:\n",
      " [[ 9.97700928e-01 -2.38692532e-04]\n",
      " [-2.38692532e-04  9.98784661e-01]]\n",
      "Cross cov:\n",
      "[[-0.00185533  0.00850044]\n",
      " [ 0.00395453 -0.00873363]]\n",
      "Cov with cov full:\n",
      "[[ 1.09977009e+01 -2.38692532e-04]\n",
      " [-2.38692532e-04  1.09987847e+01]]\n",
      "==================================================\n",
      "Analytic mean:\n",
      "[1.0009076  0.99734086]\n",
      "Analytic cov:\n",
      "[[10.99399027  0.01221628]\n",
      " [ 0.01221628 10.98131739]]\n"
     ]
    }
   ],
   "source": [
    "m, c = eq_agent.match_moments(mean_full, cov_full)\n",
    "print(50 * '=')\n",
    "print(f\"Analytic mean:\\n{m}\")\n",
    "print(f\"Analytic cov:\\n{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'joint_dist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-06f24b6f8d5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoint_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meq_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'joint_dist' is not defined"
     ]
    }
   ],
   "source": [
    "num_samples = 10**3\n",
    "\n",
    "emp_costs = []\n",
    "\n",
    "for s in trange(num_samples):\n",
    "    \n",
    "    sample = joint_dist.sample()\n",
    "    \n",
    "    c = eq_cost(sample)\n",
    "    \n",
    "    emp_costs.append(c)\n",
    "    \n",
    "emp_costs = tf.stack(emp_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_cost = tf.reduce_mean(emp_costs)\n",
    "emp_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_cost.expected_cost(loc=mean_full,\n",
    "                      cov=cov_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking accuracy of GP dynamics model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_transitions_uniformly(num_episodes, num_steps, seed):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Create pendulum environment from Gym\n",
    "    env = Environment(name='Pendulum-v0')\n",
    "    env.reset()\n",
    "    \n",
    "    state_actions = []\n",
    "    next_states = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "\n",
    "        state = env.reset()\n",
    "\n",
    "        state = np.array([np.pi, 8]) * (2 * np.random.uniform(size=(2,)) - 1)\n",
    "        env.env.env.state = state\n",
    "\n",
    "\n",
    "        for step in range(num_steps):\n",
    "\n",
    "            action = tf.random.uniform(shape=()) * 4. - 2\n",
    "            state, action, next_state = env.step(action[None].numpy())\n",
    "            \n",
    "            state_action = np.concatenate([state, action], axis=0)\n",
    "            \n",
    "            state_actions.append(state_action)\n",
    "            next_states.append(next_state)\n",
    "            \n",
    "    state_actions = np.stack(state_actions, axis=0)\n",
    "    next_states = np.stack(next_states, axis=0)\n",
    "            \n",
    "    return state_actions, next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent_dynamics(agent, test_data):\n",
    "    \n",
    "    test_inputs, test_outputs = test_data\n",
    "    \n",
    "    pred_means, pred_vars = agent.gp_posterior_predictive(test_inputs)\n",
    "    pred_means = pred_means + test_inputs[:, :2]\n",
    "    \n",
    "    sq_diff = tf.math.squared_difference(pred_means,\n",
    "                                         test_outputs)\n",
    "    \n",
    "    max_diff = tf.reduce_max(sq_diff ** 0.5, axis=0)\n",
    "    min_diff = tf.reduce_min(sq_diff ** 0.5, axis=0)\n",
    "    \n",
    "    rmse = tf.reduce_mean(sq_diff, axis=0) ** 0.5\n",
    "    smse = tf.reduce_mean(sq_diff / pred_vars, axis=0)\n",
    "    \n",
    "    rmse = [round(num, 3) for num in rmse.numpy()]\n",
    "    smse = [round(num, 3) for num in smse.numpy()]\n",
    "    max_diff = [round(num, 3) for num in max_diff.numpy()]\n",
    "    min_diff = [round(num, 3) for num in min_diff.numpy()]\n",
    "    \n",
    "    print(f'RMSE: {rmse} SMSE {smse} Min {min_diff} Max {max_diff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
       "array([ 0.        ,  1.10063546,  1.62490614,  2.01091775,  2.25060616,\n",
       "        2.49596148,  2.72551987,  2.93264035,  3.08131323,  3.25744446,\n",
       "        3.40711989,  3.54545977,  3.70617489,  3.86446703,  4.016283  ,\n",
       "        4.17855919,  4.35790156,  4.5213279 ,  4.63969456,  4.82173785,\n",
       "        4.97942248,  5.14372672,  5.3145127 ,  5.4690288 ,  5.63773962,\n",
       "        5.81552562,  5.9987452 ,  6.19443251,  6.38362588,  6.57661843,\n",
       "        6.74367591,  6.9952209 ,  7.23087437,  7.43436501,  7.69809812,\n",
       "        7.97421631,  8.26074753,  8.5363077 ,  8.83518304,  9.18606769,\n",
       "        9.53671423,  9.85136613, 10.19600471, 10.58047959, 11.08966064,\n",
       "       11.75246638, 12.47036638, 13.27642822, 14.0227504 , 16.40752203])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_policy = RBFPolicy(state_dim=2,\n",
    "                       action_dim=1,\n",
    "                       num_rbf_features=5,\n",
    "                       dtype=tf.float64)\n",
    "rbf_policy.reset()\n",
    "\n",
    "eq_cost = EQCost(target_loc=tf.ones((1, 3)),\n",
    "                 target_scale=1.,\n",
    "                 dtype=tf.float64)\n",
    "\n",
    "eq_agent = EQGPAgent(state_dim=2,\n",
    "                     action_dim=1,\n",
    "                     policy=rbf_policy,\n",
    "                     cost=eq_cost,\n",
    "                     dtype=tf.float64)\n",
    "\n",
    "train_state_actions, train_next_states = sample_transitions_uniformly(100, 1, seed=0)\n",
    "\n",
    "eq_agent.observe(train_state_actions[:, :2], train_state_actions[:, 2:3], train_next_states)\n",
    "\n",
    "eq_agent.set_eq_scales_from_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [0.009, 0.077] SMSE [0.004, 0.576] Min [0.0, 0.0] Max [0.068, 0.555]\n"
     ]
    }
   ],
   "source": [
    "test_data = sample_transitions_uniformly(1000, 1, seed=1)\n",
    "\n",
    "evaluate_agent_dynamics(eq_agent, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
