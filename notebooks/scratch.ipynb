{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pilco.policies import RBFPolicy, TransformedPolicy\n",
    "\n",
    "from pilco.transforms import SineTransform, CosineTransform\n",
    "\n",
    "from pilco.agents.agents import EQGPAgent\n",
    "from pilco.costs.costs import EQCost\n",
    "from pilco.environments import Environment\n",
    "\n",
    "from pilco.utils import get_complementary_indices\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = tf.range(3) + 1\n",
    "cov = loc[None, :] * loc[:, None]\n",
    "\n",
    "rep = 3\n",
    "\n",
    "indices = tf.convert_to_tensor([0], dtype=tf.int32)[:, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [2, 4, 6],\n",
       "       [3, 6, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_replicate(loc, cov, indices):\n",
    "    \n",
    "    indices_a = indices\n",
    "    indices_b = get_complementary_indices(indices[:, 0], 3)[:, None]\n",
    "\n",
    "    indices_aa = tf.stack(tf.meshgrid(indices_a, indices_a), axis=2)\n",
    "    indices_bb = tf.stack(tf.meshgrid(indices_b, indices_b), axis=2)\n",
    "\n",
    "    indices_ab = tf.stack(tf.meshgrid(indices_b, indices_a), axis=2)\n",
    "    indices_ba = tf.stack(tf.meshgrid(indices_a, indices_b), axis=2)\n",
    "    \n",
    "    loc_a = tf.gather_nd(loc, indices_a)\n",
    "    loc_b = tf.gather_nd(loc, indices_b)\n",
    "    \n",
    "    rep_loc_a = tf.tile(loc_a, [rep])\n",
    "    \n",
    "    rep_loc = tf.concat([rep_loc_a])\n",
    "    \n",
    "    cov_aa = tf.gather_nd(cov, indices_aa) \n",
    "    cov_ab = tf.gather_nd(cov, indices_ab) \n",
    "    cov_ba = tf.gather_nd(cov, indices_ba) \n",
    "    cov_bb = tf.gather_nd(cov, indices_bb) \n",
    "    \n",
    "    rep_cov_aa = tf.tile(cov_aa, [rep, rep])\n",
    "    rep_cov_ab = tf.tile(cov_ab, [rep, 1])\n",
    "    rep_cov_ba = tf.tile(cov_ba, [1, rep])\n",
    "\n",
    "    row_blocks = [\n",
    "        tf.concat([rep_cov_aa, rep_cov_ab], axis=1),\n",
    "        tf.concat([rep_cov_ba, cov_bb], axis=1),\n",
    "    ]\n",
    "\n",
    "    rep_cov = tf.concat(row_blocks, axis=0)\n",
    "    rep_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy: match moments (closed form and MC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_policy = RBFPolicy(2, 1, 5, dtype=tf.float32)\n",
    "rbf_policy.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All eigenvalues are postive: True\n",
      "mean_full:\n",
      "[[0.        0.        3.3896322]]\n",
      "cov_full:\n",
      "[[ 1.          0.         -0.23119213]\n",
      " [ 0.          1.         -0.00218966]\n",
      " [-0.23119213 -0.00218966  0.15528679]]\n"
     ]
    }
   ],
   "source": [
    "loc = tf.zeros(2, dtype=tf.float32)\n",
    "cov = tf.eye(2, dtype=tf.float32)\n",
    "\n",
    "mean_full, cov_full = rbf_policy.match_moments(loc, cov)\n",
    "\n",
    "print('All eigenvalues are postive:', bool(tf.reduce_all(tf.cast(tf.linalg.eig(cov_full)[0], dtype=tf.float32) > 0)))\n",
    "\n",
    "print(f'mean_full:\\n{mean_full.numpy()}')\n",
    "print(f'cov_full:\\n{cov_full.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10**3\n",
    "\n",
    "states = []\n",
    "actions = []\n",
    "\n",
    "for i in trange(num_samples):\n",
    "    \n",
    "    s = tf.random.normal(mean=0., stddev=1., shape=(2,))\n",
    "    \n",
    "    u = rbf_policy(s)\n",
    "    \n",
    "    states.append(s)\n",
    "    actions.append(u)\n",
    "    \n",
    "s = tf.convert_to_tensor(states)\n",
    "u = tf.convert_to_tensor(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "su_samples = tf.concat([s, u[..., None]], axis=-1)\n",
    "\n",
    "print('MC mean_full:')\n",
    "mean_full = tf.reduce_mean(su_samples, axis=0)[None, ...]\n",
    "print(mean_full.numpy())\n",
    "\n",
    "print('MC cov_full:')\n",
    "cov_full = (tf.einsum('ij, ik -> jk', su_samples, su_samples) / su_samples.shape[0])\n",
    "cov_full = cov_full - (tf.einsum('ij, ik -> jk', mean_full, mean_full) / mean_full.shape[0])\n",
    "print(cov_full.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sine Bounded RBF Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_policy = RBFPolicy(2, 1, 5, dtype=tf.float32)\n",
    "\n",
    "sine_transform = SineTransform(lower=-2, upper=10)\n",
    "\n",
    "sb_rbf_policy = TransformedPolicy(rbf_policy, sine_transform)\n",
    "sb_rbf_policy.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All eigenvalues are postive: True\n",
      "mean_full:\n",
      "[[0.         0.         8.99164918]]\n",
      "cov_full:\n",
      "[[ 1.          0.         -0.04156292]\n",
      " [ 0.          1.         -0.16028283]\n",
      " [-0.04156292 -0.16028283  1.6227232 ]]\n"
     ]
    }
   ],
   "source": [
    "loc = tf.zeros(2, dtype=tf.float32)\n",
    "cov = tf.eye(2, dtype=tf.float32)\n",
    "\n",
    "# mean_full_ = tf.convert_to_tensor([[ 0.,        0.,         -0.25994033]], dtype=tf.float32)\n",
    "# cov_full_ = tf.convert_to_tensor([[1.,         0.,         0.09250697],\n",
    "#  [0.,         1.,         0.06342697],\n",
    "#  [0.09250697, 0.06342697, 0.16243385]], dtype=tf.float32)\n",
    "\n",
    "# joint_dist_ = tfd.MultivariateNormalTriL(loc=mean_full_,\n",
    "#                                         scale_tril=tf.linalg.cholesky(cov_full_))\n",
    "\n",
    "mean_full, cov_full = sb_rbf_policy.match_moments(loc, cov)\n",
    "\n",
    "print('All eigenvalues are postive:', bool(tf.reduce_all(tf.cast(tf.linalg.eig(cov_full)[0], dtype=tf.float32) > 0)))\n",
    "\n",
    "print(f'mean_full:\\n{mean_full.numpy()}')\n",
    "print(f'cov_full:\\n{cov_full.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 456.90it/s]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10**3\n",
    "\n",
    "states = []\n",
    "actions = []\n",
    "\n",
    "for i in trange(num_samples):\n",
    "    \n",
    "#     samp = joint_dist_.sample()\n",
    "#     s = samp[0, :2]\n",
    "    s = tf.random.normal(mean=0., stddev=1., shape=(2,))\n",
    "    \n",
    "    u = sb_rbf_policy(s)\n",
    "    \n",
    "    states.append(s)\n",
    "    actions.append(u)\n",
    "    \n",
    "s = tf.cast(tf.convert_to_tensor(states), tf.float64)\n",
    "u = tf.convert_to_tensor(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC mean_full:\n",
      "[[0.01733977 0.00899722 8.98237663]]\n",
      "MC cov_full:\n",
      "tf.Tensor(\n",
      "[[ 0.9984372  -0.02884954 -0.17893441]\n",
      " [-0.02884954  0.95945043 -0.22250973]\n",
      " [-0.17893441 -0.22250973  1.77884097]], shape=(3, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "su_samples = tf.concat([s, u], axis=-1)\n",
    "\n",
    "print('MC mean_full:')\n",
    "mean_full = tf.reduce_mean(su_samples, axis=0)[None, ...]\n",
    "print(mean_full.numpy())\n",
    "\n",
    "print('MC cov_full:')\n",
    "cov_full = (tf.einsum('ij, ik -> jk', su_samples, su_samples) / su_samples.shape[0])\n",
    "cov_full = cov_full - (tf.einsum('ij, ik -> jk', mean_full, mean_full) / mean_full.shape[0])\n",
    "print(cov_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent: match moments (closed form and MC)\n",
    "\n",
    "## Add dummy data to agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gergelyflamich/Documents/sbrml/pilco/pilco-venv/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(24)\n",
    "\n",
    "rbf_policy = RBFPolicy(state_dim=2,\n",
    "                       action_dim=1,\n",
    "                       num_rbf_features=5,\n",
    "                       dtype=tf.float64)\n",
    "\n",
    "sine_transform = SineTransform(lower=-20,\n",
    "                               upper=15)\n",
    "\n",
    "sb_rbf_policy = TransformedPolicy(rbf_policy,\n",
    "                                  sine_transform)\n",
    "\n",
    "# rbf_policy.reset()\n",
    "sb_rbf_policy.reset()\n",
    "\n",
    "cost_transform = CosineTransform(lower=-1,\n",
    "                                 upper=1)\n",
    "\n",
    "eq_cost = EQCost(target_loc=tf.ones((1, 3)),\n",
    "                 target_scale=1.,\n",
    "                 transform=cost_transform,\n",
    "                 dtype=tf.float64)\n",
    "\n",
    "eq_agent = EQGPAgent(state_dim=2,\n",
    "                     action_dim=1,\n",
    "                     policy=sb_rbf_policy,\n",
    "                     cost=eq_cost,\n",
    "                     dtype=tf.float64)\n",
    "\n",
    "# Create pendulum environment from Gym\n",
    "env = Environment(name='Pendulum-v0')\n",
    "env.reset()\n",
    "\n",
    "num_episodes = 50\n",
    "num_steps = 1\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    \n",
    "    state = env.reset()\n",
    "    \n",
    "    state = np.array([np.pi, 8]) * (2 * np.random.uniform(size=(2,)) - 1)\n",
    "    env.env.env.state = state\n",
    "    \n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        \n",
    "        action = tf.random.uniform(shape=()) * 4. - 2\n",
    "        state, action, next_state = env.step(action[None].numpy())\n",
    "        \n",
    "        eq_agent.observe(state, action, next_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match moments analytically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state_loc = 1. * tf.ones(2, dtype=tf.float64)\n",
    "state_cov = 10. * tf.eye(2, dtype=tf.float64)\n",
    "\n",
    "# Match moments for the joint state-action distribution\n",
    "mean_full, cov_full = sb_rbf_policy.match_moments(state_loc, state_cov)\n",
    "\n",
    "# mean_full = 0. * tf.ones((1, 3), dtype=tf.float64)\n",
    "# cov_full = 1. * tf.eye(3, dtype=tf.float64)\n",
    "\n",
    "joint_dist = tfd.MultivariateNormalTriL(loc=mean_full,\n",
    "                                        scale_tril=tf.linalg.cholesky(cov_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match moments by MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:15<00:00, 63.75it/s]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10**3\n",
    "\n",
    "means = []\n",
    "covs = []\n",
    "state_actions = []\n",
    "\n",
    "# MC approx\n",
    "for i in trange(num_samples):\n",
    "    \n",
    "    state_action = joint_dist.sample()\n",
    "    \n",
    "    #Note: mean is the expectation of the deltas!\n",
    "    mean, cov = eq_agent.gp_posterior_predictive(state_action)\n",
    "    means.append(mean)\n",
    "    \n",
    "    covs.append(cov)\n",
    "    state_actions.append(state_action)\n",
    "    \n",
    "means = tf.concat(means, axis=0)\n",
    "covs = tf.stack(covs, axis=0)\n",
    "state_actions = tf.stack(state_actions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cov[E(Δ | x)]:\n",
      "[[ 4.65782609e-05 -1.53337716e-04]\n",
      " [-1.50575380e-04  5.40089927e-04]]\n",
      "E[Cov(Δ | x)]:\n",
      "[[0.99916862 0.        ]\n",
      " [0.         0.99916862]]\n",
      "Cov[x, Δ]:\n",
      "[[-0.001178    0.00455786]\n",
      " [ 0.00233944 -0.00669134]]\n",
      "Emp mean:\n",
      "[[1.00049665 0.99826535]]\n",
      "Emp cov:\n",
      "[[1.09968592e+01 6.74396022e-03]\n",
      " [6.74672256e-03 1.09863260e+01]]\n"
     ]
    }
   ],
   "source": [
    "emp_mean = tf.reduce_mean(means, axis=0)\n",
    "\n",
    "cov_mean_delta = tf.reduce_mean(means[:, None, :] * means[:, :, None], axis=0)\n",
    "cov_mean_delta = cov_mean_delta - emp_mean * tf.transpose(emp_mean)\n",
    "print(f'Cov[E(Δ | x)]:\\n{cov_mean_delta}')\n",
    "mean_cov_delta = tf.linalg.diag(tf.reduce_mean(covs, axis=[0, 1]))\n",
    "print(f'E[Cov(Δ | x)]:\\n{mean_cov_delta}')\n",
    "\n",
    "states = state_actions[:, :, :eq_agent.state_dim]\n",
    "emp_cross_cov = tf.reduce_mean(states * means[:, :, None], axis=0)\n",
    "emp_cross_cov = emp_cross_cov - tf.reduce_mean(states, axis=0) * tf.reduce_mean(means[:, :, None], axis=0)\n",
    "print(f\"Cov[x, Δ]:\\n{tf.transpose(emp_cross_cov)}\")\n",
    "\n",
    "emp_mean = tf.reduce_mean(means, axis=0) + mean_full[:, :eq_agent.state_dim]\n",
    "emp_cov = cov_full[:eq_agent.state_dim, :eq_agent.state_dim] \n",
    "emp_cov = emp_cov + cov_mean_delta + mean_cov_delta + emp_cross_cov + tf.transpose(emp_cross_cov)\n",
    "print(f\"Emp mean:\\n{emp_mean}\")\n",
    "print(f\"Emp cov:\\n{emp_cov}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Analytic mean:\n",
      "[1.00072588 0.99781502]\n",
      "Analytic cov:\n",
      "[[1.09955644e+01 9.66726715e-03]\n",
      " [9.66726715e-03 1.09841003e+01]]\n"
     ]
    }
   ],
   "source": [
    "m, c = eq_agent.match_moments(mean_full, cov_full)\n",
    "print(50 * '=')\n",
    "print(f\"Analytic mean:\\n{m}\")\n",
    "print(f\"Analytic cov:\\n{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:12<00:00, 80.01it/s]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10**3\n",
    "\n",
    "emp_costs = []\n",
    "\n",
    "for s in trange(num_samples):\n",
    "    \n",
    "    sample = joint_dist.sample()\n",
    "    \n",
    "    c = eq_cost(sample)\n",
    "    \n",
    "    emp_costs.append(c)\n",
    "    \n",
    "emp_costs = tf.stack(emp_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.9999656432748208>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_cost = tf.reduce_mean(emp_costs)\n",
    "emp_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.999949897141532>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_cost.expected_cost(loc=mean_full,\n",
    "                      cov=cov_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking accuracy of GP dynamics model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_transitions_uniformly(num_episodes, num_steps, seed):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Create pendulum environment from Gym\n",
    "    env = Environment(name='Pendulum-v0')\n",
    "    env.reset()\n",
    "    \n",
    "    state_actions = []\n",
    "    next_states = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "\n",
    "        state = env.reset()\n",
    "\n",
    "        state = np.array([np.pi, 8]) * (2 * np.random.uniform(size=(2,)) - 1)\n",
    "        env.env.env.state = state\n",
    "\n",
    "\n",
    "        for step in range(num_steps):\n",
    "\n",
    "            action = tf.random.uniform(shape=()) * 4. - 2\n",
    "            state, action, next_state = env.step(action[None].numpy())\n",
    "            \n",
    "            state_action = np.concatenate([state, action], axis=0)\n",
    "            \n",
    "            state_actions.append(state_action)\n",
    "            next_states.append(next_state)\n",
    "            \n",
    "    state_actions = np.stack(state_actions, axis=0)\n",
    "    next_states = np.stack(next_states, axis=0)\n",
    "            \n",
    "    return state_actions, next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent_dynamics(agent, test_data):\n",
    "    \n",
    "    test_inputs, test_outputs = test_data\n",
    "    \n",
    "    pred_means, pred_vars = agent.gp_posterior_predictive(test_inputs)\n",
    "    pred_means = pred_means + test_inputs[:, :2]\n",
    "    \n",
    "    sq_diff = tf.math.squared_difference(pred_means,\n",
    "                                         test_outputs)\n",
    "    \n",
    "    max_diff = tf.reduce_max(sq_diff ** 0.5, axis=0)\n",
    "    min_diff = tf.reduce_min(sq_diff ** 0.5, axis=0)\n",
    "    \n",
    "    rmse = tf.reduce_mean(sq_diff, axis=0) ** 0.5\n",
    "    smse = tf.reduce_mean(sq_diff / pred_vars, axis=0)\n",
    "    \n",
    "    rmse = [round(num, 3) for num in rmse.numpy()]\n",
    "    smse = [round(num, 3) for num in smse.numpy()]\n",
    "    max_diff = [round(num, 3) for num in max_diff.numpy()]\n",
    "    min_diff = [round(num, 3) for num in min_diff.numpy()]\n",
    "    \n",
    "    print(f'RMSE: {rmse} SMSE {smse} Min {min_diff} Max {max_diff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gergelyflamich/Documents/sbrml/pilco/pilco-venv/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "rbf_policy = RBFPolicy(state_dim=2,\n",
    "                       action_dim=1,\n",
    "                       num_rbf_features=5,\n",
    "                       dtype=tf.float64)\n",
    "rbf_policy.reset()\n",
    "\n",
    "cost_tr = CosineTransform(lower=-1,\n",
    "                         upper=1)\n",
    "\n",
    "eq_cost = EQCost(target_loc=tf.ones((1, 3)),\n",
    "                 target_scale=1.,\n",
    "                 transform=cost_tr,\n",
    "                 dtype=tf.float64)\n",
    "\n",
    "eq_agent = EQGPAgent(state_dim=2,\n",
    "                     action_dim=1,\n",
    "                     policy=rbf_policy,\n",
    "                     cost=eq_cost,\n",
    "                     dtype=tf.float64)\n",
    "\n",
    "train_state_actions, train_next_states = sample_transitions_uniformly(100, 1, seed=0)\n",
    "\n",
    "eq_agent.observe(train_state_actions[:, :2], train_state_actions[:, 2:3], train_next_states)\n",
    "\n",
    "eq_agent.set_eq_scales_from_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [0.009, 0.077] SMSE [0.004, 0.576] Min [0.0, 0.0] Max [0.068, 0.555]\n"
     ]
    }
   ],
   "source": [
    "test_data = sample_transitions_uniformly(1000, 1, seed=1)\n",
    "\n",
    "evaluate_agent_dynamics(eq_agent, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean a  tf.Tensor([[0.]], shape=(1, 1), dtype=float64)\n",
      "mean a plus pi/2 tf.Tensor([[1.57079637]], shape=(1, 1), dtype=float64)\n",
      "loc, cov tf.Tensor([[1.      1.      0.99995]], shape=(1, 3), dtype=float64) tf.Tensor(\n",
      "[[4.99949981e-09 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 9.99999975e-05 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.99999975e-05]], shape=(3, 3), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=9.999374766178626e-05>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_cost.expected_cost(tf.constant([[0, 1, 1]]), 1e-4 * tf.eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
